{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/param2070/SpitMLLabtest/blob/main/MLExp4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XG6VSgvBx0_5",
        "outputId": "9a726a8f-dfda-4d9d-d0cb-438535ef089c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import io\n",
        "from sklearn import preprocessing\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "matplotlib.style.use('ggplot')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/data/amazon_alexa.tsv', sep='\\t', low_memory=False)\n",
        "df.shape\n"
      ],
      "metadata": {
        "id": "IuyhT8064QvX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "744086d7-5967-4bc4-badf-bf70e1c743d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3150, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n",
        "print(df['feedback'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1LgAoAvUdAj",
        "outputId": "a42a2813-ab71-49c8-b0fd-6f318322a5df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3150 entries, 0 to 3149\n",
            "Data columns (total 5 columns):\n",
            " #   Column            Non-Null Count  Dtype \n",
            "---  ------            --------------  ----- \n",
            " 0   rating            3150 non-null   int64 \n",
            " 1   date              3150 non-null   object\n",
            " 2   variation         3150 non-null   object\n",
            " 3   verified_reviews  3150 non-null   object\n",
            " 4   feedback          3150 non-null   int64 \n",
            "dtypes: int64(2), object(3)\n",
            "memory usage: 123.2+ KB\n",
            "1    2893\n",
            "0     257\n",
            "Name: feedback, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def preprocess_string(str_arg):\n",
        "    cleaned_str=re.sub('[^a-z\\s]+',' ',str_arg,flags=re.IGNORECASE) #every char except alphabets is replaced\n",
        "    cleaned_str=re.sub('(\\s+)',' ',cleaned_str) #multiple spaces are replaced by single space\n",
        "    cleaned_str=cleaned_str.lower() #converting the cleaned string to lower case\n",
        "    \n",
        "    return cleaned_str "
      ],
      "metadata": {
        "id": "73H1Ls4I1ZGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveBayes:\n",
        "    \n",
        "    def __init__(self,unique_classes):\n",
        "        self.classes=unique_classes \n",
        "        \n",
        "\n",
        "    def addToBow(self,example,dict_index):\n",
        "        if isinstance(example,np.ndarray): example=example[0]\n",
        "        for token_word in example.split(): \n",
        "            self.bow_dicts[dict_index][token_word]+=1 \n",
        "\n",
        "\n",
        "    def train(self,dataset,labels):\n",
        "        self.examples=dataset\n",
        "        self.labels=labels\n",
        "        self.bow_dicts=np.array([defaultdict(lambda:0) for index in range(self.classes.shape[0])])        \n",
        "        if not isinstance(self.examples,np.ndarray): self.examples=np.array(self.examples)\n",
        "        if not isinstance(self.labels,np.ndarray): self.labels=np.array(self.labels)\n",
        "            \n",
        "        for cat_index,cat in enumerate(self.classes): \n",
        "            all_cat_examples=self.examples[self.labels==cat]           \n",
        "            cleaned_examples=[preprocess_string(cat_example) for cat_example in all_cat_examples]\n",
        "            cleaned_examples=pd.DataFrame(data=cleaned_examples)\n",
        "            np.apply_along_axis(self.addToBow,1,cleaned_examples,cat_index)\n",
        "            \n",
        "      \n",
        "        prob_classes=np.empty(self.classes.shape[0])\n",
        "        all_words=[]\n",
        "        cat_word_counts=np.empty(self.classes.shape[0])\n",
        "        for cat_index,cat in enumerate(self.classes):\n",
        "           \n",
        "            prob_classes[cat_index]=np.sum(self.labels==cat)/float(self.labels.shape[0]) \n",
        "            \n",
        "            count=list(self.bow_dicts[cat_index].values())\n",
        "            cat_word_counts[cat_index]=np.sum(np.array(list(self.bow_dicts[cat_index].values())))+1 \n",
        "            \n",
        "            all_words+=self.bow_dicts[cat_index].keys()\n",
        "                                                     \n",
        "        self.vocab=np.unique(np.array(all_words))\n",
        "        self.vocab_length=self.vocab.shape[0]\n",
        "                                  \n",
        "        denoms=np.array([cat_word_counts[cat_index]+self.vocab_length+1 for cat_index,cat in enumerate(self.classes)])                                                                          \n",
        "      \n",
        "        self.cats_info=[(self.bow_dicts[cat_index],prob_classes[cat_index],denoms[cat_index]) for cat_index,cat in enumerate(self.classes)]                               \n",
        "        self.cats_info=np.array(self.cats_info)                                 \n",
        "                                              \n",
        "                                           \n",
        "    def getExampleProb(self,test_example):                                                              \n",
        "        likelihood_prob=np.zeros(self.classes.shape[0]) \n",
        "        \n",
        "        for cat_index,cat in enumerate(self.classes): \n",
        "                             \n",
        "            for test_token in test_example.split(): \n",
        "                                        \n",
        "                test_token_counts=self.cats_info[cat_index][0].get(test_token,0)+1\n",
        "                \n",
        "                test_token_prob=test_token_counts/float(self.cats_info[cat_index][2])                              \n",
        "                \n",
        "                likelihood_prob[cat_index]+=np.log(test_token_prob)\n",
        "                                              \n",
        "        post_prob=np.empty(self.classes.shape[0])\n",
        "        for cat_index,cat in enumerate(self.classes):\n",
        "            post_prob[cat_index]=likelihood_prob[cat_index]+np.log(self.cats_info[cat_index][1])                                  \n",
        "      \n",
        "        return post_prob\n",
        "    \n",
        "   \n",
        "    def test(self,test_set):       \n",
        "        predictions=[] \n",
        "        for example in test_set:                                           \n",
        "            cleaned_example=preprocess_string(example)           \n",
        "            post_prob=self.getExampleProb(cleaned_example)\n",
        "            predictions.append(self.classes[np.argmax(post_prob)])         \n",
        "        return np.array(predictions)\n"
      ],
      "metadata": {
        "id": "vZST7Ma02m2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train=df['feedback'].values\n",
        "x_train=df['verified_reviews'].values\n",
        "print (\"Unique Classes: \",np.unique(y_train))\n",
        "print (\"Total Number of Training Examples: \",x_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvI8UAgV7tgs",
        "outputId": "76cddcd1-8895-4d45-91cc-fae5223e2644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique Classes:  [0 1]\n",
            "Total Number of Training Examples:  (3150,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from collections import defaultdict\n",
        "import re\n",
        "train_data,test_data,train_labels,test_labels=train_test_split(x_train,y_train,shuffle=True,test_size=0.25,random_state=42,stratify=y_train)\n",
        "classes=np.unique(train_labels)"
      ],
      "metadata": {
        "id": "nSq-mGTV8CEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb=NaiveBayes(classes)\n",
        "print (\"Training Examples: \",train_data.shape)\n",
        "nb.train(train_data,train_labels)\n",
        "pclasses=nb.test(test_data)\n",
        "test_acc=np.sum(pclasses==test_labels)/float(test_labels.shape[0])\n",
        "print (\"Test Set Examples: \",test_labels.shape[0])\n",
        "print (\"Test Set Accuracy: \",test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LvL2tLH8RUr",
        "outputId": "df7fcb14-e82d-4ea9-a843-30b6f9ab8e27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Examples:  (2362,)\n",
            "Test Set Examples:  788\n",
            "Test Set Accuracy:  0.934010152284264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_matrix(pclasses, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0Tenp8T9QFy",
        "outputId": "12a5ca63-131a-446f-8bd5-7276dd781ef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 22,  10],\n",
              "       [ 42, 714]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}